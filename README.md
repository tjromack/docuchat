```markdown
# DocuChat - Document Chat Assistant with RAG

A production-ready document chat assistant that allows users to upload documents and ask questions about their content using Retrieval Augmented Generation (RAG).

## Project Status

**Phase 1 Complete**: Document upload and management system âœ…
- âœ… File upload with validation
- âœ… Text extraction from PDF/DOCX/TXT
- âœ… Document metadata storage
- âœ… RESTful API endpoints
- âœ… Interactive API documentation

**Phase 2 Complete**: RAG Implementation Core âœ…
- âœ… Text chunking with configurable overlap strategy
- âœ… Vector embeddings (sentence-transformers)
- âœ… ChromaDB vector database integration
- âœ… Semantic similarity search
- âœ… Chat endpoint for Q&A
- âœ… Complete RAG pipeline (retrieve â†’ augment â†’ generate)
- âœ… Source attribution with similarity scores
- ğŸ“ Mock LLM responses for demo (OpenAI integration ready)

**Phase 3 Complete**: Frontend Interface âœ…
- âœ… Modern, responsive web interface
- âœ… Document upload with drag-and-drop
- âœ… Real-time chat with message history
- âœ… Source citation display
- âœ… Mobile-friendly design
- âœ… Loading states and notifications
- âœ… Production-ready UI/UX

## Features

- **Multi-format Document Support**: PDF, DOCX, and TXT files
- **Intelligent Text Processing**: Automatic chunking with semantic overlap
- **Vector Search**: Fast similarity search using ChromaDB
- **Source Citations**: Every answer includes source documents with similarity scores
- **Clean UI**: Modern, responsive interface built with vanilla HTML/CSS/JS
- **RESTful API**: FastAPI-based backend with automatic documentation
- **Demo Mode**: Fully functional RAG retrieval with mock LLM responses

## Tech Stack

**Backend:**
- Python 3.8+
- FastAPI - Modern web framework
- SQLAlchemy - Database ORM
- ChromaDB - Vector database
- sentence-transformers - Text embeddings
- PyPDF2, python-docx - Document processing

**Frontend:**
- HTML5/CSS3/JavaScript (Vanilla)
- No build tools required
- Responsive design

## Quick Start

### Prerequisites

- Python 3.8+
- Git

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/tjromack/docuchat.git
   cd docuchat
   ```

2. **Set up the backend**
   ```bash
   cd backend
   python -m venv venv
   
   # Windows
   .\venv\Scripts\activate
   
   # macOS/Linux
   source venv/bin/activate
   
   pip install -r requirements.txt
   ```

3. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env with your settings (optional: add OpenAI API key for real LLM responses)
   ```

4. **Run the backend**
   ```bash
   python -m app.main
   ```
   Backend will be available at http://localhost:8000

5. **Run the frontend (new terminal)**
   ```bash
   cd frontend
   python -m http.server 8080
   ```
   Frontend will be available at http://localhost:8080

## Usage

1. **Upload Documents**: Click "+ Upload" or drag and drop PDF, DOCX, or TXT files
2. **Wait for Processing**: Documents are automatically chunked and vectorized
3. **Ask Questions**: Type questions in natural language about your documents
4. **View Sources**: See which document chunks were used to generate the answer

## API Endpoints

### Documents
- `POST /api/documents/upload` - Upload and process a document
- `GET /api/documents/` - List all documents
- `GET /api/documents/{id}` - Get specific document details
- `DELETE /api/documents/{id}` - Delete a document

### Chat
- `POST /api/chat/ask` - Ask a question about documents
  - Request body: `{"question": "string", "document_id": int (optional), "n_results": 5}`
  - Returns answer with source citations

### Health
- `GET /health` - Health check endpoint

## Project Structure

```
docuchat/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ models/          # Database models
â”‚   â”‚   â”œâ”€â”€ routers/         # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ documents.py
â”‚   â”‚   â”‚   â””â”€â”€ chat.py
â”‚   â”‚   â”œâ”€â”€ services/        # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ text_extractor.py
â”‚   â”‚   â”‚   â”œâ”€â”€ text_chunker.py
â”‚   â”‚   â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â”‚   â””â”€â”€ document_processor.py
â”‚   â”‚   â””â”€â”€ main.py          # FastAPI application
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ app.js
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/             # Uploaded files
â”‚   â”œâ”€â”€ vectordb/           # ChromaDB storage
â”‚   â””â”€â”€ processed/          # Processed documents
â””â”€â”€ README.md
```

## Configuration

Environment variables in `.env`:

```env
OPENAI_API_KEY=your_openai_api_key_here (optional - for real LLM responses)
DATABASE_URL=sqlite:///./docuchat.db
UPLOAD_FOLDER=../data/uploads
VECTOR_DB_PATH=../data/vectordb
```

**Note**: The application works without an OpenAI API key using mock responses that demonstrate the RAG retrieval pipeline. Add an API key to get AI-generated answers.

## Architecture

**RAG Pipeline Flow:**
1. **Document Upload** â†’ Text extraction â†’ Chunking (500 chars, 100 overlap)
2. **Embedding** â†’ sentence-transformers generates 384-dim vectors
3. **Storage** â†’ Chunks and embeddings stored in ChromaDB
4. **Query** â†’ User question â†’ Embedding â†’ Similarity search
5. **Retrieval** â†’ Top 5 relevant chunks retrieved
6. **Generation** â†’ Context + Question â†’ LLM â†’ Answer with sources

## Development

### Run Tests
```bash
cd backend
python test_chunking.py
python test_embeddings.py
python test_vector_store.py
```

### Access API Documentation
Visit http://localhost:8000/docs for interactive API documentation

## Future Enhancements

- Real OpenAI/Anthropic LLM integration (currently using mock responses)
- Local LLM support with Ollama
- Multi-user authentication
- Document collections/workspaces
- Conversation history persistence
- Advanced filtering and search
- Export conversation transcripts
- Support for more file formats (markdown, CSV, etc.)

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Contact

Project Link: https://github.com/tjromack/docuchat

## Acknowledgments

Built as a learning project to demonstrate:
- Retrieval Augmented Generation (RAG) architecture
- Vector database integration
- Modern web development practices
- Clean API design
- Production-ready code structure
```
